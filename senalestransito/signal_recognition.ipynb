{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Directory containing reference images\n",
    "images_dir = \"C:/Users/Amy Diaz/Documents/pyrobo/senalestransito\"\n",
    "\n",
    "# Initialize ORB detector\n",
    "orb = cv2.ORB_create(nfeatures=100)#, scaleFactor=1.2, nlevels=8)\n",
    "\n",
    "# Initialize camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Unable to open the camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    # Read frames\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Check if the frame is captured successfully\n",
    "    if not ret:\n",
    "        print(\"Error: Unable to capture frame\")\n",
    "        break\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply edge detection\n",
    "    edges = cv2.Canny(frame_gray, 20, 60)\n",
    "\n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Copy the original image to draw contours\n",
    "    image_contours = frame.copy()\n",
    "\n",
    "    # Iterate over each contour\n",
    "    for contour in contours:\n",
    "        # Calculate epsilon: the approximation accuracy\n",
    "        epsilon = 0.02 # * cv2.arcLength(contour, True)\n",
    "\n",
    "        # Approximate the contour\n",
    "        approx = cv2.approxPolyDP(contour, epsilon, True)\n",
    "        \n",
    "        # Draw the original contour (in green)\n",
    "        cv2.drawContours(image_contours, [contour], -1, (0, 255, 0), 2)\n",
    "        # Draw the approximated contour (in red)\n",
    "        cv2.drawContours(image_contours, [approx], -1, (0, 0, 255), 2)\n",
    "\n",
    "    # Detect ORB features in the frame\n",
    "    keypoints_frame, descriptors_frame = orb.detectAndCompute(frame_gray, None)\n",
    "\n",
    "    # Initialize variables to store the best match\n",
    "    best_match_filename = None\n",
    "    best_match_count = 0\n",
    "\n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(images_dir):\n",
    "        # Load the image\n",
    "        img = cv2.imread(os.path.join(images_dir, filename))\n",
    "\n",
    "        # Check if the image is loaded successfully\n",
    "        if img is not None:\n",
    "            # Convert the image to grayscale\n",
    "            img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect ORB features in the image\n",
    "            keypoints_img, descriptors_img = orb.detectAndCompute(img_gray, None)\n",
    "\n",
    "            # Create feature matcher\n",
    "            bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "            # Match descriptors of both images\n",
    "            if descriptors_frame is not None and descriptors_img is not None:\n",
    "                matches = bf.match(descriptors_frame, descriptors_img)\n",
    "                match_count = len(matches)\n",
    "\n",
    "                # If the current image has more matches than the previous best match, update the best match\n",
    "                if match_count > best_match_count:\n",
    "                    best_match_filename = filename\n",
    "                    best_match_count = match_count\n",
    "\n",
    "    # Show the best matched image\n",
    "    if best_match_filename is not None:\n",
    "        print(f\"Best match: {best_match_filename}, Matches: {best_match_count}\")\n",
    "        matched_image = cv2.imread(os.path.join(images_dir, best_match_filename))\n",
    "        matched_image = cv2.resize(matched_image, (frame.shape[1], frame.shape[0]))  # Resize to match frame size\n",
    "        combined_output = cv2.hconcat([image_contours, matched_image])  # Combine frame and matched image horizontally\n",
    "        cv2.imshow('Matched Image', combined_output)\n",
    "    else:\n",
    "        print(\"No match found\")\n",
    "        cv2.imshow('Matched Image', image_contours)\n",
    "\n",
    "    # Break the loop if Enter or Esc key is pressed\n",
    "    keyboard = cv2.waitKey(1)\n",
    "    if keyboard in (13, 27):\n",
    "        break\n",
    "\n",
    "# Release the camera and destroy all windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
